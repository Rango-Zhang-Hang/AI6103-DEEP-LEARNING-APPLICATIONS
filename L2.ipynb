{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rango-Zhang-Hang/AI6103-DEEP-LEARNING-APPLICATIONS/blob/main/L2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET_BWAqFQBOL",
        "outputId": "5c9952fe-dcd3-4225-fe30-919c33b61497"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6fUQ8dxTk4f",
        "outputId": "0dca4c7c-15de-4cdc-a43d-6d6435791ed6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas \n",
        "import io\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf  \n",
        "\n",
        "torch.manual_seed(1024);"
      ],
      "metadata": {
        "id": "cZK9WaEdyOIN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data\n",
        "1 for positive, 0 for negative "
      ],
      "metadata": {
        "id": "eyf8MJaVspjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pandas.read_csv('./gdrive/MyDrive/IMDB Dataset.csv')\n",
        "dataset.sentiment = dataset.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
        "dataset.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aZc73BF4yR6-",
        "outputId": "6dc2276d-f811-4cb5-92a3-e36cea1fa6ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e6beb2c-f917-4b64-b8c8-b62bbe7f5da8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e6beb2c-f917-4b64-b8c8-b62bbe7f5da8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e6beb2c-f917-4b64-b8c8-b62bbe7f5da8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e6beb2c-f917-4b64-b8c8-b62bbe7f5da8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Validation"
      ],
      "metadata": {
        "id": "50c_94MEyaoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['val'] = 0\n",
        "# Randomlize\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "# get label\n",
        "label = dataset.sentiment.values\n",
        "\n",
        "validation = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "for val, (train_, valid_) in enumerate(validation.split(X=dataset, y=label)):\n",
        "    dataset.loc[valid_, 'val'] = val\n",
        "dataset.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z37jb_40soKE",
        "outputId": "b70fb1db-c390-419b-a3c6-f8c16235ae2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment  val\n",
              "0  Love In Limbo is my all-time favoirite movie. ...          1    0\n",
              "1  This is a wonderful film taking place during t...          1    0\n",
              "2  This may not be one of the best movies ever ma...          1    0\n",
              "3  I watched it last night and again this morning...          1    0\n",
              "4  You know the movie could have been a lot bette...          0    0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f4c1a77-414d-4c17-9424-325269125af9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Love In Limbo is my all-time favoirite movie. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a wonderful film taking place during t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This may not be one of the best movies ever ma...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I watched it last night and again this morning...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You know the movie could have been a lot bette...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f4c1a77-414d-4c17-9424-325269125af9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f4c1a77-414d-4c17-9424-325269125af9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f4c1a77-414d-4c17-9424-325269125af9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-trained\n",
        "word embedding"
      ],
      "metadata": {
        "id": "tWfqns9b0daH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('loading word embeddings...')\n",
        "embed_model = {}\n",
        "embed_file = codecs.open('./gdrive/MyDrive/wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "for line in tqdm(embed_file):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embed_model[word] = coefs\n",
        "embed_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxxRZlfa0fXD",
        "outputId": "20a9cd3d-e00f-416b-9407-cca620f045c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "999995it [01:46, 9410.74it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model['hi'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU9OLLGe-l_X",
        "outputId": "0fdfae28-4280-49a2-8cdd-45de4d3be17a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Pipline"
      ],
      "metadata": {
        "id": "BIEeariJ_Cx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IMDBDataset:\n",
        "    def __init__(self, reviews, targets):\n",
        "        \"\"\"\n",
        "        Argument:\n",
        "        reviews: a numpy array\n",
        "        targets: a vector array\n",
        "        \n",
        "        Return xtrain and ylabel in torch tensor datatype, stored in dictionary format\n",
        "        \"\"\"\n",
        "        self.reviews = reviews\n",
        "        self.target = targets\n",
        "    \n",
        "    def __len__(self):\n",
        "        # return length of dataset\n",
        "        return len(self.reviews)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # given an idex (item), return review and target of that index in torch tensor\n",
        "        review = torch.tensor(self.reviews[index,:], dtype = torch.long)\n",
        "        target = torch.tensor(self.target[index], dtype = torch.float)\n",
        "        \n",
        "        return {'review': review,\n",
        "                'target': target}"
      ],
      "metadata": {
        "id": "Jh-h7amo_BGh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        \"\"\"\n",
        "        Given embedding_matrix: numpy array with vector for all words\n",
        "        return prediction ( in torch tensor format)\n",
        "        \"\"\"\n",
        "        super(LSTM, self).__init__()\n",
        "        # Number of words = number of rows in embedding matrix\n",
        "        num_words = embedding_matrix.shape[0]\n",
        "        # Dimension of embedding is num of columns in the matrix\n",
        "        embedding_dim = embedding_matrix.shape[1]\n",
        "        # Define an input embedding layer\n",
        "        self.embedding = nn.Embedding(\n",
        "                                      num_embeddings=num_words,\n",
        "                                      embedding_dim=embedding_dim)\n",
        "        # Embedding matrix actually is collection of parameter\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n",
        "        # Because we use pretrained embedding (GLove, Fastext,etc) so we turn off requires_grad-meaning we do not train gradient on embedding weight\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        # LSTM with hidden_size = 128\n",
        "        self.lstm = nn.LSTM(\n",
        "                            embedding_dim, \n",
        "                            128,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True,\n",
        "                             )\n",
        "        # Input(512) because we use bi-directional LSTM ==> hidden_size*2 + maxpooling **2  = 128*4 = 512, will be explained more on forward method\n",
        "        self.out = nn.Linear(512, 1)\n",
        "    def forward(self, x):\n",
        "        # pass input (tokens) through embedding layer\n",
        "        x = self.embedding(x)\n",
        "        # fit embedding to LSTM\n",
        "        hidden, _ = self.lstm(x)\n",
        "        # apply mean and max pooling on lstm output\n",
        "        avg_pool= torch.mean(hidden, 1)\n",
        "        max_pool, index_max_pool = torch.max(hidden, 1)\n",
        "        # concat avg_pool and max_pool ( so we have 256 size, also because this is bidirectional ==> 256*2 = 512)\n",
        "        out = torch.cat((avg_pool, max_pool), 1)\n",
        "        # fit out to self.out to conduct dimensionality reduction from 512 to 1\n",
        "        out = self.out(out)\n",
        "        # return output\n",
        "        return out"
      ],
      "metadata": {
        "id": "c6qWf0bj_CUM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, optimizer, device):\n",
        "    \"\"\"\n",
        "    this is model training for one epoch\n",
        "    data_loader:  this is torch dataloader, just like dataset but in torch and devide into batches\n",
        "    model : lstm\n",
        "    optimizer : torch optimizer : adam\n",
        "    device:  cuda or cpu\n",
        "    \"\"\"\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    # go through batches of data in data loader\n",
        "    for data in data_loader:\n",
        "        reviews = data['review']\n",
        "        targets = data['target']\n",
        "        # move the data to device that we want to use\n",
        "        reviews = reviews.to(device, dtype = torch.long)\n",
        "        targets = targets.to(device, dtype = torch.float)\n",
        "        # clear the gradient\n",
        "        optimizer.zero_grad()\n",
        "        # make prediction from model\n",
        "        predictions = model(reviews)\n",
        "        # caculate the losses\n",
        "        loss = nn.BCEWithLogitsLoss()(predictions, targets.view(-1,1))\n",
        "        # backprob\n",
        "        loss.backward()\n",
        "        #single optimization step\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "ci-pDx3KAlEt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader, model, device):\n",
        "    final_predictions = []\n",
        "    final_targets = []\n",
        "    model.eval()\n",
        "    # turn off gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            reviews = data['review']\n",
        "            targets = data['target']\n",
        "            reviews = reviews.to(device, dtype = torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "            # make prediction\n",
        "            predictions = model(reviews)\n",
        "            # move prediction and target to cpu\n",
        "            predictions = predictions.cpu().numpy().tolist()\n",
        "            targets = data['target'].cpu().numpy().tolist()\n",
        "            # add predictions to final_prediction\n",
        "            final_predictions.extend(predictions)\n",
        "            final_targets.extend(targets)\n",
        "    return final_predictions, final_targets"
      ],
      "metadata": {
        "id": "XQDZVB-TAqeY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Config"
      ],
      "metadata": {
        "id": "bBuR2lajAuFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "tdXe3VZgAsbi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(word_index, embedding_dict=None, d_model=100):\n",
        "    \"\"\"\n",
        "     this function create the embedding matrix save in numpy array\n",
        "    :param word_index: a dictionary with word: index_value\n",
        "    :param embedding_dict: a dict with word embedding\n",
        "    :d_model: the dimension of word pretrained embedding, here I just set to 100, we will define again\n",
        "    :return a numpy array with embedding vectors for all known words\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, d_model))\n",
        "    ## loop over all the words\n",
        "    for word, index in word_index.items():\n",
        "        if word in embedding_dict:\n",
        "            embedding_matrix[index] = embedding_dict[word]\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "jU-HcM2JAzW9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VZZEF6CWBCvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenize"
      ],
      "metadata": {
        "id": "bU2hdHgZcYBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(dataset.review.values.tolist())"
      ],
      "metadata": {
        "id": "JxgSQ9uLBEO9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Load embed model')"
      ],
      "metadata": {
        "id": "EGOKmDcOcXw_",
        "outputId": "c9805b41-e39d-4c8d-884a-a940219f9ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load embed model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=embed_model, d_model=300)"
      ],
      "metadata": {
        "id": "kcSGUQ11ykAz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "torch.cuda.is_available()\n",
        "#tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "tM8BgCu12T0B",
        "outputId": "de0a10e8-277e-4906-aa57-e8f1c970ecae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more fold to get better generalization\n",
        "for fold in range(10):\n",
        "    # STEP 2: cross validation\n",
        "    train_dataset = dataset[dataset.val != fold].reset_index(drop=True)\n",
        "    valid_dataset = dataset[dataset.val == fold].reset_index(drop=True)\n",
        "    \n",
        "    # STEP 3: pad sequence\n",
        "    xtrain = tokenizer.texts_to_sequences(train_dataset.review.values)\n",
        "    xtest = tokenizer.texts_to_sequences(valid_dataset.review.values)\n",
        "    \n",
        "    # zero padding\n",
        "    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n",
        "    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
        "    \n",
        "    # STEP 4: initialize dataset class for training\n",
        "    train_dataset = IMDBDataset(reviews=xtrain, targets=train_dataset.sentiment.values)\n",
        "    \n",
        "    # STEP 5: Load dataset to Pytorch DataLoader\n",
        "    # after we have train_dataset, we create a torch dataloader to load train_dataset class based on specified batch_size\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n",
        "    # initialize dataset class for validation\n",
        "    valid_dataset = IMDBDataset(reviews=xtest, targets=valid_dataset.sentiment.values)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n",
        "    \n",
        "    # STEP 6: Running \n",
        "    device = torch.device('cpu')\n",
        "    # feed embedding matrix to lstm\n",
        "    model_fasttext = LSTM(embedding_matrix)\n",
        "    # set model to cuda device\n",
        "    model_fasttext.to(device)\n",
        "    # initialize Adam optimizer\n",
        "    optimizer = torch.optim.Adam(model_fasttext.parameters(), lr=1e-3)\n",
        "    \n",
        "    print('training model')\n",
        "   \n",
        "    for epoch in range(EPOCHS):\n",
        "        #train one epoch\n",
        "        train(train_data_loader, model_fasttext, optimizer, device)\n",
        "        #validate\n",
        "        outputs, targets = evaluate(valid_data_loader, model_fasttext, device)\n",
        "        # threshold\n",
        "        outputs = np.array(outputs) >= 0.5\n",
        "        # calculate accuracy\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')"
      ],
      "metadata": {
        "id": "uIna3BlMzo3k",
        "outputId": "c111d2b2-4c93-47d2-a0a7-5bc120806133",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model\n",
            "FOLD:0, epoch: 0, accuracy_score: 0.8653\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User input"
      ],
      "metadata": {
        "id": "36pKsgzf8nQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Interact_user_input(model):\n",
        "    '''\n",
        "    model: trained model : fasttext model or glove model\n",
        "    '''\n",
        "    model.eval()\n",
        "    \n",
        "    sentence = ''\n",
        "    while True:\n",
        "        try:\n",
        "            sentence = input('Review: ')\n",
        "            if sentence in ['q','quit']: \n",
        "                break\n",
        "            sentence = np.array([sentence])\n",
        "            sentence_token = tokenizer.texts_to_sequences(sentence)\n",
        "            sentence_token = tf.keras.preprocessing.sequence.pad_sequences(sentence_token, maxlen = MAX_LEN)\n",
        "            sentence_train = torch.tensor(sentence_token, dtype = torch.long).to(device, dtype = torch.long)\n",
        "            predict = model(sentence_train)\n",
        "            if predict.item() > 0.5:\n",
        "                print('------> Positive')\n",
        "            else:\n",
        "                print('------> Negative')\n",
        "        except KeyError:\n",
        "            print('please enter again')\n",
        "   "
      ],
      "metadata": {
        "id": "dJFan0yt8o7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Interact_user_input(model_fasttext)"
      ],
      "metadata": {
        "id": "cFSEUSQJ8uWB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}