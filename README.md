# AI6103-DEEP-LEARNING-APPLICATIONS
Project

This project studies the effects of regularization and optimization on the BERT model. Sentiment classification is performed on the IMDB dataset (50k movie reviews) with a pre-trained BERT model. We experimented with 5 different techniques: optimizers, dropout, L2 regularization, early stopping, and data  augmentation. The results obtained are compared with a baseline model. 

## Code Contribution
| Name  | Algorithm |
| ------------- | ------------- |
| Ding Hongwei  | Optimizers  |
| Lam See Hwee  | Early Stopping  |
|Loy Yong Yi Wendy|Dropout|
|Seah Xiu Xuan Sherbelle|Data augmentation|
|Zhang Hang|L2 Regularization|

## Reference
BERT baseline model: [BERT](https://www.kaggle.com/code/houssemayed/imdb-sentiment-classification-with-bert/notebook)

IMDB review dataset: [IMDB](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)
